{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2df32b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshmisrinidhpachabotla/Desktop/scl_ml_dl/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import os\n",
    "from zoneinfo import ZoneInfo\n",
    "import requests\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a90de5",
   "metadata": {},
   "source": [
    "Login and create a hopworks project with api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa18272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 23:38:20,341 INFO: Initializing external client\n",
      "2026-01-05 23:38:20,341 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.6.0 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 23:38:21,963 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1301658\n",
      "Connected to Hopsworks project: Air_Pollution_AQI_2026\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PROJECT_NAME = \"Air_Pollution_AQI_2026\"\n",
    "HOPSWORKS_API_KEY = \"TdfX0A4MLqJC0IIn.sAY3ZbpVnGwgbRwCnjibbiEhsVy5hrlFPyIg6Rr2yHW8ptEKRhJ3OEx0an3itvtw\"\n",
    "\n",
    "project = hopsworks.login(\n",
    "    project=PROJECT_NAME,\n",
    "    api_key_value=HOPSWORKS_API_KEY\n",
    ")\n",
    "\n",
    "print(f\"Connected to Hopsworks project: {project.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b5f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TZ = ZoneInfo(\"America/New_York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "978726f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after JFK filter: 10732\n",
      "Columns available: 16\n"
     ]
    }
   ],
   "source": [
    "path_dataset = \"data/10_2024.csv\"\n",
    "df = pd.read_csv(path_dataset, low_memory=False)\n",
    "\n",
    "# Filter to JFK only\n",
    "df = df[df[\"ORIGIN\"] == \"JFK\"].copy()\n",
    "\n",
    "print(\"Rows after JFK filter:\", len(df))\n",
    "print(\"Columns available:\", len(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d172df9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after removing cancelled/diverted: 10651\n"
     ]
    }
   ],
   "source": [
    "# 2) Drop cancelled/diverted flights (recommended)\n",
    "df[\"CANCELLED\"] = pd.to_numeric(df[\"CANCELLED\"], errors=\"coerce\").fillna(0)\n",
    "df[\"DIVERTED\"] = pd.to_numeric(df[\"DIVERTED\"], errors=\"coerce\").fillna(0)\n",
    "df = df[(df[\"CANCELLED\"] == 0) & (df[\"DIVERTED\"] == 0)].copy()\n",
    "print(\"Rows after removing cancelled/diverted:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b815b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = [\n",
    "    \"QUARTER\", \"MONTH\", \"DAY_OF_MONTH\", \"DAY_OF_WEEK\",\n",
    "    \"FL_DATE\", \"CRS_DEP_TIME\",\n",
    "    \"OP_UNIQUE_CARRIER\", \"DEST\", \"DISTANCE\",\n",
    "    \"DEP_DELAY\"\n",
    "]\n",
    "missing = [c for c in keep_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "df = df[keep_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a79b5c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# TIME CLEANING\n",
    "# ----------------------------\n",
    "# CRS_DEP_TIME -> 4-digit string \"HHMM\"\n",
    "df[\"CRS_DEP_TIME\"] = pd.to_numeric(df[\"CRS_DEP_TIME\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"FL_DATE\", \"CRS_DEP_TIME\"])\n",
    "\n",
    "df[\"CRS_DEP_TIME\"] = df[\"CRS_DEP_TIME\"].astype(int).astype(str).str.zfill(4)\n",
    "\n",
    "# FL_DATE -> date (ignore time portion)\n",
    "df[\"FL_DATE\"] = pd.to_datetime(df[\"FL_DATE\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"FL_DATE\"])\n",
    "\n",
    "# Build scheduled departure local timestamp\n",
    "df[\"sched_dep_local\"] = pd.to_datetime(\n",
    "    df[\"FL_DATE\"].dt.strftime(\"%Y-%m-%d\") + \" \" + df[\"CRS_DEP_TIME\"],\n",
    "    format=\"%Y-%m-%d %H%M\",\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "df = df.dropna(subset=[\"sched_dep_local\"])\n",
    "df[\"sched_dep_local\"] = df[\"sched_dep_local\"].dt.tz_localize(TZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5fbd71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# TARGET CLEANING (keep raw dep_delay as requested)\n",
    "# ----------------------------\n",
    "df[\"DEP_DELAY\"] = pd.to_numeric(df[\"DEP_DELAY\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d5cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# PRIMARY KEY\n",
    "# ----------------------------\n",
    "df[\"flight_id\"] = (\n",
    "    \"JFK_\" +\n",
    "    df[\"DEST\"].astype(str) + \"_\" +\n",
    "    df[\"OP_UNIQUE_CARRIER\"].astype(str) + \"_\" +\n",
    "    df[\"sched_dep_local\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4edebbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               flight_id           sched_dep_local  quarter  \\\n",
      "85  JFK_BGR_9E_2024-10-01 22:15:00-04:00 2024-10-01 22:15:00-04:00        4   \n",
      "86  JFK_BTV_9E_2024-10-01 09:59:00-04:00 2024-10-01 09:59:00-04:00        4   \n",
      "87  JFK_BTV_9E_2024-10-01 22:45:00-04:00 2024-10-01 22:45:00-04:00        4   \n",
      "88  JFK_BUF_9E_2024-10-01 09:29:00-04:00 2024-10-01 09:29:00-04:00        4   \n",
      "89  JFK_BUF_9E_2024-10-01 12:59:00-04:00 2024-10-01 12:59:00-04:00        4   \n",
      "\n",
      "    month  day_of_month  day_of_week crs_dep_time reporting_airline dest  \\\n",
      "85     10             1            2         2215                9E  BGR   \n",
      "86     10             1            2         0959                9E  BTV   \n",
      "87     10             1            2         2245                9E  BTV   \n",
      "88     10             1            2         0929                9E  BUF   \n",
      "89     10             1            2         1259                9E  BUF   \n",
      "\n",
      "    distance  dep_delay  \n",
      "85     382.0      -12.0  \n",
      "86     266.0       -8.0  \n",
      "87     266.0      -10.0  \n",
      "88     301.0       -5.0  \n",
      "89     301.0       21.0  \n",
      "Final rows: 10651\n",
      "Unique flight_id: 10651\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# FINAL DATAFRAME (rename to clean names)\n",
    "# ----------------------------\n",
    "df_fg = df.rename(columns={\n",
    "    \"QUARTER\": \"quarter\",\n",
    "    \"MONTH\": \"month\",\n",
    "    \"DAY_OF_MONTH\": \"day_of_month\",\n",
    "    \"DAY_OF_WEEK\": \"day_of_week\",\n",
    "    \"CRS_DEP_TIME\": \"crs_dep_time\",\n",
    "    \"OP_UNIQUE_CARRIER\": \"reporting_airline\",\n",
    "    \"DEST\": \"dest\",\n",
    "    \"DISTANCE\": \"distance\",\n",
    "    \"DEP_DELAY\": \"dep_delay\",\n",
    "})\n",
    "\n",
    "df_fg = df_fg[\n",
    "    [\n",
    "        \"flight_id\",\n",
    "        \"sched_dep_local\",\n",
    "        \"quarter\",\n",
    "        \"month\",\n",
    "        \"day_of_month\",\n",
    "        \"day_of_week\",\n",
    "        \"crs_dep_time\",\n",
    "        \"reporting_airline\",\n",
    "        \"dest\",\n",
    "        \"distance\",\n",
    "        \"dep_delay\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "print(df_fg.head())\n",
    "print(\"Final rows:\", len(df_fg))\n",
    "print(\"Unique flight_id:\", df_fg[\"flight_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b412c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 23:47:11,920 INFO: Closing external client and cleaning up certificates.\n",
      "2026-01-05 23:47:11,923 INFO: Connection closed.\n",
      "2026-01-05 23:47:11,925 INFO: Initializing external client\n",
      "2026-01-05 23:47:11,925 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.6.0 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 23:47:13,324 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1301658\n"
     ]
    },
    {
     "ename": "FeatureStoreException",
     "evalue": "Failed to write to delta table in external cluster. Make sure datanode load balancer has been setup on the cluster.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRestAPIError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scl_ml_dl/.venv/lib/python3.13/site-packages/hopsworks_common/core/variable_api.py:126\u001b[39m, in \u001b[36mVariableApi.get_loadbalancer_external_domain\u001b[39m\u001b[34m(self, service)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_variable\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mloadbalancer_external_domain_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mservice\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RestAPIError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scl_ml_dl/.venv/lib/python3.13/site-packages/hopsworks_common/core/variable_api.py:52\u001b[39m, in \u001b[36mVariableApi.get_variable\u001b[39m\u001b[34m(self, variable)\u001b[39m\n\u001b[32m     51\u001b[39m path_params = [\u001b[33m\"\u001b[39m\u001b[33mvariables\u001b[39m\u001b[33m\"\u001b[39m, variable]\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m domain = \u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m domain[\u001b[33m\"\u001b[39m\u001b[33msuccessMessage\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scl_ml_dl/.venv/lib/python3.13/site-packages/hopsworks_common/decorators.py:48\u001b[39m, in \u001b[36mconnected.<locals>.if_connected\u001b[39m\u001b[34m(inst, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scl_ml_dl/.venv/lib/python3.13/site-packages/hopsworks_common/client/base.py:186\u001b[39m, in \u001b[36mClient._send_request\u001b[39m\u001b[34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code // \u001b[32m100\u001b[39m != \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.RestAPIError(url, response)\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
      "\u001b[31mRestAPIError\u001b[39m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/variables/loadbalancer_external_domain_datanode). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":100050,\"usrMsg\":\"Variable: loadbalancer_external_domain_datanodenot found\",\"errorMsg\":\"Requested variable not found\"}', error code: 100050, error msg: Requested variable not found, user msg: Variable: loadbalancer_external_domain_datanodenot found",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mFeatureStoreException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scl_ml_dl/.venv/lib/python3.13/site-packages/hsfs/core/delta_engine.py:285\u001b[39m, in \u001b[36mDeltaEngine._setup_delta_rs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     datanode_ip = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loadbalancer_external_domain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdatanode\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    287\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m     _logger.debug(\n\u001b[32m    289\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSetting HOPSFS_CLOUD_DATANODE_HOSTNAME_OVERRIDE to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatanode_ip\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    290\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scl_ml_dl/.venv/lib/python3.13/site-packages/hopsworks_common/core/variable_api.py:129\u001b[39m, in \u001b[36mVariableApi.get_loadbalancer_external_domain\u001b[39m\u001b[34m(self, service)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err.STATUS_CODE_NOT_FOUND:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m FeatureStoreException(\n\u001b[32m    130\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClient could not get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLOADBALANCER_SERVICES[service]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service hostname from \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    131\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mloadbalancer_external_domain_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mservice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    132\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe variable is either not set or empty in Hopsworks cluster configuration.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFeatureStoreException\u001b[39m: Client could not get datanode service hostname from loadbalancer_external_domain_datanode. The variable is either not set or empty in Hopsworks cluster configuration.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mFeatureStoreException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      5\u001b[39m fs = project.get_feature_store()\n\u001b[32m      7\u001b[39m bts_fg = fs.get_or_create_feature_group(\n\u001b[32m      8\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mbts_jfk_selected_features_fg\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     version=\u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     description=\u001b[33m\"\u001b[39m\u001b[33mBTS JFK departures: selected predictors + dep_delay target\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mbts_fg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_fg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstart_offline_materialization\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInserted month into bts_jfk_selected_features_fg v1\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scl_ml_dl/.venv/lib/python3.13/site-packages/hsfs/feature_group.py:3454\u001b[39m, in \u001b[36mFeatureGroup.insert\u001b[39m\u001b[34m(self, features, overwrite, operation, storage, write_options, validation_options, wait, transformation_context, transform)\u001b[39m\n\u001b[32m   3444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m   3445\u001b[39m     [\n\u001b[32m   3446\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._id,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3450\u001b[39m ):\n\u001b[32m   3451\u001b[39m     \u001b[38;5;66;03m# New delta FG allow for change data capture query\u001b[39;00m\n\u001b[32m   3452\u001b[39m     write_options[\u001b[33m\"\u001b[39m\u001b[33mdelta.enableChangeDataFeed\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m3454\u001b[39m job, ge_report = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_feature_group_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3455\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3457\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3458\u001b[39m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m=\u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3459\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   3460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msave_report\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3462\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformation_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3464\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3466\u001b[39m \u001b[38;5;66;03m# Compute stats in client if there is no backfill job:\u001b[39;00m\n\u001b[32m   3467\u001b[39m \u001b[38;5;66;03m# - spark engine: always compute in client\u001b[39;00m\n\u001b[32m   3468\u001b[39m \u001b[38;5;66;03m# - python engine: only compute if FG is offline only (no backfill job)\u001b[39;00m\n\u001b[32m   3469\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine.get_type().startswith(\u001b[33m\"\u001b[39m\u001b[33mspark\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scl_ml_dl/.venv/lib/python3.13/site-packages/hsfs/core/feature_group_engine.py:247\u001b[39m, in \u001b[36mFeatureGroupEngine.insert\u001b[39m\u001b[34m(self, feature_group, feature_dataframe, overwrite, operation, storage, write_options, validation_options, transformation_context, transform)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m overwrite:\n\u001b[32m    244\u001b[39m     \u001b[38;5;28mself\u001b[39m._feature_group_api.delete_content(feature_group)\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbulk_insert\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m.\u001b[49m\u001b[43monline_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffline_write_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43monline_write_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    256\u001b[39m     ge_report,\n\u001b[32m    257\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scl_ml_dl/.venv/lib/python3.13/site-packages/hsfs/engine/python.py:1084\u001b[39m, in \u001b[36mEngine.save_dataframe\u001b[39m\u001b[34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[39m\n\u001b[32m   1082\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine.get_type() == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1083\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m feature_group.time_travel_format == \u001b[33m\"\u001b[39m\u001b[33mDELTA\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1084\u001b[39m         delta_engine_instance = \u001b[43mdelta_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDeltaEngine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfeature_store_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature_store_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfeature_store_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature_store_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m            \u001b[49m\u001b[43mspark_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m            \u001b[49m\u001b[43mspark_session\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1091\u001b[39m         delta_engine_instance.save_delta_fg(\n\u001b[32m   1092\u001b[39m             dataframe,\n\u001b[32m   1093\u001b[39m             write_options=offline_write_options,\n\u001b[32m   1094\u001b[39m             validation_id=validation_id,\n\u001b[32m   1095\u001b[39m         )\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1097\u001b[39m     \u001b[38;5;66;03m# for backwards compatibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scl_ml_dl/.venv/lib/python3.13/site-packages/hsfs/core/delta_engine.py:76\u001b[39m, in \u001b[36mDeltaEngine.__init__\u001b[39m\u001b[34m(self, feature_store_id, feature_store_name, feature_group, spark_session, spark_context)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28mself\u001b[39m._variable_api = variable_api.VariableApi()\n\u001b[32m     75\u001b[39m \u001b[38;5;28mself\u001b[39m._project_api = project_api.ProjectApi()\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_delta_rs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scl_ml_dl/.venv/lib/python3.13/site-packages/hsfs/core/delta_engine.py:293\u001b[39m, in \u001b[36mDeltaEngine._setup_delta_rs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mHOPSFS_CLOUD_DATANODE_HOSTNAME_OVERRIDE\u001b[39m\u001b[33m\"\u001b[39m] = datanode_ip\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m FeatureStoreException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m FeatureStoreException(\n\u001b[32m    294\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to write to delta table in external cluster. Make sure datanode load balancer has been setup on the cluster.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    295\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    297\u001b[39m user_name = \u001b[38;5;28mself\u001b[39m._project_api.get_user_info().get(\u001b[33m\"\u001b[39m\u001b[33musername\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    299\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_name:\n",
      "\u001b[31mFeatureStoreException\u001b[39m: Failed to write to delta table in external cluster. Make sure datanode load balancer has been setup on the cluster."
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# HOPSWORKS\n",
    "# ----------------------------\n",
    "project = hopsworks.login(project=PROJECT_NAME, api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "bts_fg = fs.get_or_create_feature_group(\n",
    "    name=\"bts_jfk_selected_features_fg\",\n",
    "    version=1,\n",
    "    primary_key=[\"flight_id\"],\n",
    "    event_time=\"sched_dep_local\",\n",
    "    description=\"BTS JFK departures: selected predictors + dep_delay target\"\n",
    ")\n",
    "\n",
    "bts_fg.insert(df_fg, write_options={\"wait_for_job\": True})\n",
    "\n",
    "print(\"Inserted month into bts_jfk_selected_features_fg v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6b7f3",
   "metadata": {},
   "source": [
    "Get Weather data from Open Mateo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# ----------------------------\n",
    "# 1) Derive START_DATE / END_DATE from BTS df_fg\n",
    "# ----------------------------\n",
    "TZ_NAME = \"America/New_York\"\n",
    "TZ = ZoneInfo(TZ_NAME)\n",
    "\n",
    "# df_fg should already exist from your BTS cleaning cell\n",
    "# Ensure sched_dep_local is datetime\n",
    "df_fg[\"sched_dep_local\"] = pd.to_datetime(df_fg[\"sched_dep_local\"], errors=\"coerce\")\n",
    "df_fg = df_fg.dropna(subset=[\"sched_dep_local\"])\n",
    "\n",
    "min_ts = df_fg[\"sched_dep_local\"].min()\n",
    "max_ts = df_fg[\"sched_dep_local\"].max()\n",
    "\n",
    "START_DATE = min_ts.date().isoformat()\n",
    "END_DATE = max_ts.date().isoformat()\n",
    "\n",
    "print(\"Derived weather range from BTS:\")\n",
    "print(\"START_DATE =\", START_DATE)\n",
    "print(\"END_DATE   =\", END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0181f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# ----------------------------\n",
    "# 2) Fetch Open-Meteo hourly historical weather for JFK\n",
    "#    (exact variables you requested)\n",
    "# ----------------------------\n",
    "LAT = 40.6413\n",
    "LON = -73.7781\n",
    "\n",
    "OPEN_METEO_HIST_URL = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "HOURLY_VARS = [\n",
    "    \"weathercode\",\n",
    "    \"windspeed_10m\",\n",
    "    \"windgusts_10m\",\n",
    "    \"temperature_2m\",\n",
    "    \"precipitation\",\n",
    "    \"snowfall\",\n",
    "    \"visibility\",\n",
    "]\n",
    "\n",
    "params = {\n",
    "    \"latitude\": LAT,\n",
    "    \"longitude\": LON,\n",
    "    \"start_date\": START_DATE,\n",
    "    \"end_date\": END_DATE,\n",
    "    \"hourly\": \",\".join(HOURLY_VARS),\n",
    "    \"timezone\": TZ_NAME,  # return timestamps in NY local time\n",
    "}\n",
    "\n",
    "resp = requests.get(OPEN_METEO_HIST_URL, params=params, timeout=60)\n",
    "resp.raise_for_status()\n",
    "data = resp.json()\n",
    "\n",
    "if \"hourly\" not in data or \"time\" not in data[\"hourly\"]:\n",
    "    raise ValueError(f\"Unexpected Open-Meteo response structure. Top-level keys: {list(data.keys())}\")\n",
    "\n",
    "hourly = data[\"hourly\"]\n",
    "print(\"✅ Open-Meteo response received. Hours:\", len(hourly[\"time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2abdbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# ----------------------------\n",
    "# 3) Build weather dataframe (hourly) with clean schema\n",
    "# ----------------------------\n",
    "times = pd.to_datetime(hourly[\"time\"], errors=\"coerce\")\n",
    "\n",
    "# Open-Meteo returns local timestamps when timezone is specified, usually as naive strings.\n",
    "# Localize to America/New_York safely around DST.\n",
    "weather_hour_local = times.dt.tz_localize(\n",
    "    TZ,\n",
    "    ambiguous=\"infer\",\n",
    "    nonexistent=\"shift_forward\"\n",
    ")\n",
    "\n",
    "df_weather = pd.DataFrame({\n",
    "    \"weather_hour_local\": weather_hour_local\n",
    "})\n",
    "\n",
    "# Rename to our stored feature names\n",
    "df_weather[\"weather_code\"]   = hourly.get(\"weathercode\")        # WMO code\n",
    "df_weather[\"wind_speed_ms\"]  = hourly.get(\"windspeed_10m\")\n",
    "df_weather[\"wind_gust_ms\"]   = hourly.get(\"windgusts_10m\")\n",
    "df_weather[\"temp_c\"]         = hourly.get(\"temperature_2m\")\n",
    "df_weather[\"precip_mm\"]      = hourly.get(\"precipitation\")\n",
    "df_weather[\"snowfall_cm\"]    = hourly.get(\"snowfall\")\n",
    "df_weather[\"visibility_m\"]   = hourly.get(\"visibility\")\n",
    "\n",
    "# Primary key for each weather hour\n",
    "df_weather[\"weather_id\"] = df_weather[\"weather_hour_local\"].astype(str)\n",
    "\n",
    "# Optional metadata (handy for debugging)\n",
    "df_weather[\"station\"] = \"JFK\"\n",
    "df_weather[\"latitude\"] = float(LAT)\n",
    "df_weather[\"longitude\"] = float(LON)\n",
    "\n",
    "# Force numeric types where appropriate\n",
    "num_cols = [\n",
    "    \"weather_code\",\n",
    "    \"wind_speed_ms\",\n",
    "    \"wind_gust_ms\",\n",
    "    \"temp_c\",\n",
    "    \"precip_mm\",\n",
    "    \"snowfall_cm\",\n",
    "    \"visibility_m\",\n",
    "]\n",
    "for c in num_cols:\n",
    "    df_weather[c] = pd.to_numeric(df_weather[c], errors=\"coerce\")\n",
    "\n",
    "df_weather = df_weather.dropna(subset=[\"weather_hour_local\"])\n",
    "\n",
    "# Final column order for Hopsworks\n",
    "df_weather_fg = df_weather[\n",
    "    [\n",
    "        \"weather_id\",\n",
    "        \"weather_hour_local\",\n",
    "        \"station\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"weather_code\",\n",
    "        \"wind_speed_ms\",\n",
    "        \"wind_gust_ms\",\n",
    "        \"temp_c\",\n",
    "        \"precip_mm\",\n",
    "        \"snowfall_cm\",\n",
    "        \"visibility_m\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "print(df_weather_fg.head())\n",
    "print(\"Rows:\", len(df_weather_fg))\n",
    "print(\"Min hour:\", df_weather_fg[\"weather_hour_local\"].min())\n",
    "print(\"Max hour:\", df_weather_fg[\"weather_hour_local\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a16e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# ----------------------------\n",
    "# 4) Create/Insert into Hopsworks Weather Feature Group\n",
    "# ----------------------------\n",
    "# Assumes you already have: project, fs from earlier BTS code\n",
    "# If not, uncomment below:\n",
    "# import hopsworks\n",
    "# project = hopsworks.login(project=PROJECT_NAME, api_key_value=API_KEY)\n",
    "# fs = project.get_feature_store()\n",
    "\n",
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name=\"weather_jfk_hourly_fg\",\n",
    "    version=1,\n",
    "    primary_key=[\"weather_id\"],\n",
    "    event_time=\"weather_hour_local\",\n",
    "    description=\"Hourly JFK weather from Open-Meteo (weathercode, wind, temp, precip, snowfall, visibility)\"\n",
    ")\n",
    "\n",
    "weather_fg.insert(df_weather_fg, write_options={\"wait_for_job\": True})\n",
    "\n",
    "print(\"✅ Feature group created/updated: weather_jfk_hourly_fg v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b778a67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9da0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711f4750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
